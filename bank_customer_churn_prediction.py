# -*- coding: utf-8 -*-
"""Bank_Customer_Churn_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U4KEgOkVh14iPda0t6XljB1Btg8yyMd2
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import classification_report, plot_confusion_matrix

data = pd.read_csv('Bank Customer Churn Prediction.csv')

data

print(f"Data Frame Size: {data.shape}")

data.info()

data.describe()

data.isna().sum()

target = (
    data
    .churn
    .value_counts()
    .reset_index()
)

plt.figure(dpi=100)

sns.barplot(x='index', y='churn', data=target)

plt.figure(dpi=150)
sns.displot(data=data, x='age', hue='churn', kind='kde')

plt.figure(dpi=150)
sns.displot(data=data, x='age', hue='country', kind='kde', fill=True)

country_churn = (data
                .groupby(['churn'])['country']
                .value_counts()
                .rename('count')
                .reset_index())

print(country_churn)

plt.figure(figsize=(10, 8), dpi=100)

ax = sns.barplot(data=country_churn, x='country', y='count', hue='churn')

for p in ax.patches:
  count = f"{p.get_height()}"

  print(p.get_x() + p.get_width() / 2., p.get_height())
  ax.annotate(
      count,
      (p.get_x() + p.get_width() / 2., p.get_height()),
      ha='center',
      va='center',
      xytext=(0, 10),
      textcoords="offset points"
  )

active_members = (
    data.groupby(['churn'])['active_member'].value_counts().rename('count').reset_index()
    
)

print()

plt.figure(figsize=(10, 8), dpi=100)

ax = sns.barplot(data=active_members, x=active_members['active_member'].map({0: 'No', 1 : 'Yes'}), y='count', hue='churn')

for p in ax.patches:
  count = f"{p.get_height()}"
  ax.annotate(
      count,
      (p.get_x() + p.get_width() / 2., p.get_height()),
      ha='center',
      va='center',
      xytext=(0, 10),
      textcoords="offset points"
  )

sns.displot(data=data, x=data.estimated_salary.sort_values(), kind='kde', hue='churn')

print(data.estimated_salary.min())

sns.displot(data=data, x=data.tenure.sort_values(), kind='kde', hue='churn')

plt.figure(dpi=100)
sns.heatmap(data=data.corr())

data = pd.get_dummies(data)

data = data.drop('customer_id', axis=1)

X = data.drop('churn', axis=1)
y = data['churn']

sc = StandardScaler()

X = sc.fit_transform(X)

X

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

lr = LogisticRegression()
lr.fit(X_train, y_train)

preds = lr.predict(X_test)

print(classification_report(y_test, preds))

grid_params = {
    'penalty': ['l1', 'l2', 'elasticnet'],
    'C': [0.001, 0.1, 1, 3, 5, 7],
    'max_iter': np.linspace(1, 100, 10)
}

lr_grid = LogisticRegression()

grid = GridSearchCV(lr_grid, grid_params, verbose=2)

grid.fit(X_train, y_train)

grid.best_estimator_

final_lr = LogisticRegression(penalty='l2', C=0.1, max_iter=12.0)

def get_model_preds(model):
  model.fit(X_train, y_train)
  preds = model.predict(X_test)
  print(classification_report(y_test, preds))

final_lr.fit(X_train, y_train)

preds = lr.predict(X_test)

print(classification_report(y_test, preds))

svc = SVC()

get_model_preds(svc)

grid_params = {
    'C': [0.01, 0.1, 1, 3, 5],
    'kernel': ['poly', 'rbf', 'sigmoid'],
    'gamma': ['auto'],
    'degree': [1, 3, 5, 7]
}

svc_grid = SVC()

grid = GridSearchCV(svc_grid, grid_params, verbose=2)

grid.fit(X_train, y_train)

grid.best_params_

final_svc = SVC(C=5, degree=3, gamma='auto', kernel='poly')

get_model_preds(final_svc)

KNN = KNeighborsClassifier()

get_model_preds(KNN)

grid_params = {
    'n_neighbors': [3, 5, 7, 9],
}

knn_grid = KNeighborsClassifier()

grid = GridSearchCV(knn_grid, grid_params, verbose=2)

grid.fit(X_train, y_train)

grid.best_params_

final_knn = KNeighborsClassifier(n_neighbors=7)

get_model_preds(final_knn)

rfc = RandomForestClassifier()

get_model_preds(rfc)

rfc_grid = RandomForestClassifier()

grid_params = {
    'n_estimators': [50, 100, 150],
    'max_depth': [3, 5, 7],
    'bootstrap': [True, False]
}

grid = GridSearchCV(rfc_grid, grid_params, verbose=2)

grid.fit(X_train, y_train)

grid.best_params_

final_rfc = RandomForestClassifier(n_estimators=150, bootstrap=False, max_depth=7)

get_model_preds(final_rfc)

from joblib import load, dump

dump(final_svc, 'svc_model.joblib')